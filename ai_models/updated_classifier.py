#!/usr/bin/env python3
"""
Updated Model Loader for trained_model directory
‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å trained_model
"""

import joblib
import json
import numpy as np
from pathlib import Path
from PIL import Image
import cv2
from typing import Dict, List, Tuple, Optional
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier

class UpdatedAmuletClassifier:
    """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô classifier ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà"""
    
    def __init__(self, model_path: str = "trained_model"):
        self.model_path = Path(model_path)
        self.model = None
        self.scaler = None
        self.label_encoder = None
        self.pca = None  # ‡πÄ‡∏û‡∏¥‡πà‡∏° PCA
        self.class_mapping = None
        self.model_info = None
        self.image_size = (224, 224)
        
    def load_model(self, model_path: Optional[str] = None):
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ artifacts ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        if model_path:
            self.model_path = Path(model_path)
            
        print(f"Loading model from: {self.model_path}")
        
        # ‡πÇ‡∏´‡∏•‡∏î model files
        try:
            # ‡πÇ‡∏´‡∏•‡∏î classifier
            classifier_path = self.model_path / "classifier.joblib"
            if classifier_path.exists():
                self.model = joblib.load(classifier_path)
                print("‚úÖ Loaded classifier.joblib")
            else:
                raise FileNotFoundError(f"Classifier not found: {classifier_path}")
            
            # ‡πÇ‡∏´‡∏•‡∏î scaler
            scaler_path = self.model_path / "scaler.joblib"
            if scaler_path.exists():
                self.scaler = joblib.load(scaler_path)
                print("‚úÖ Loaded scaler.joblib")
            else:
                print("‚ö†Ô∏è Scaler not found, will use raw features")
            
            # ‡πÇ‡∏´‡∏•‡∏î label encoder
            encoder_path = self.model_path / "label_encoder.joblib"
            if encoder_path.exists():
                self.label_encoder = joblib.load(encoder_path)
                print("‚úÖ Loaded label_encoder.joblib")
            else:
                print("‚ö†Ô∏è Label encoder not found")
            
            # ‡πÇ‡∏´‡∏•‡∏î PCA
            pca_path = self.model_path / "pca.joblib"
            if pca_path.exists():
                self.pca = joblib.load(pca_path)
                print("‚úÖ Loaded pca.joblib")
            else:
                print("‚ö†Ô∏è PCA not found")
            
            # ‡πÇ‡∏´‡∏•‡∏î model info
            info_path = self.model_path / "training_info.json"
            if info_path.exists():
                with open(info_path, 'r', encoding='utf-8') as f:
                    self.model_info = json.load(f)
                # ‡πÇ‡∏´‡∏•‡∏î class mapping ‡∏à‡∏≤‡∏Å labels.json
                labels_path = self.model_path / "labels.json"
                if labels_path.exists():
                    with open(labels_path, 'r', encoding='utf-8') as f:
                        labels_data = json.load(f)
                    self.class_mapping = labels_data.get('current_classes', {})
                    # ‡πÅ‡∏õ‡∏•‡∏á key ‡∏à‡∏≤‡∏Å string index ‡πÄ‡∏õ‡πá‡∏ô class name mapping
                    if self.class_mapping:
                        self.class_mapping = {v: int(k) for k, v in self.class_mapping.items()}
                self.image_size = tuple(self.model_info.get('image_size', [224, 224]))
                print("‚úÖ Loaded training_info.json and labels.json")
            else:
                print("‚ö†Ô∏è Model info not found")
            
            print(f"üéØ Model loaded successfully!")
            if self.model_info:
                print(f"üìä Accuracy: {self.model_info.get('accuracy', 'Unknown')}")
                print(f"üìÅ Classes: {len(self.class_mapping) if self.class_mapping else 'Unknown'}")
            else:
                print(f"üìÅ Classes: {len(self.class_mapping) if self.class_mapping else 'Unknown'}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            return False
    
    def extract_features(self, image: np.ndarray) -> Optional[np.ndarray]:
        """‡∏™‡∏Å‡∏±‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡∏ô‡∏¥‡πà‡∏á)"""
        try:
            if not isinstance(image, np.ndarray):
                return None
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            if len(image.shape) == 3 and image.shape[2] == 3:
                if image.dtype == np.uint8 and np.max(image) > 1:
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô BGR (OpenCV) ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            image_resized = cv2.resize(image, self.image_size)
            img_array = image_resized.astype(np.uint8)
            
            # Extract basic features (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏ô)
            features = []
            
            # Color histogram features  
            for channel in range(3):  # RGB
                hist, _ = np.histogram(img_array[:,:,channel], bins=32, range=(0, 256))
                features.extend(hist)
            
            # Statistical features
            features.extend([
                np.mean(img_array),
                np.std(img_array),
                np.var(img_array),
                np.min(img_array),
                np.max(img_array)
            ])
            
            # Shape and texture features
            gray = np.mean(img_array, axis=2)
            
            # Edge density (simplified)
            # ‡πÉ‡∏ä‡πâ Sobel edge detection
            sobel_x = cv2.Sobel(gray.astype(np.uint8), cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray.astype(np.uint8), cv2.CV_64F, 0, 1, ksize=3)
            edges = np.sqrt(sobel_x**2 + sobel_y**2)
            edge_density = np.mean(edges > np.mean(edges))
            features.append(edge_density)
            
            # Local binary pattern (simplified)
            lbp_features = self.compute_lbp_features(gray)
            features.extend(lbp_features)
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            print(f"Error extracting features: {e}")
            return None
    
    def compute_lbp_features(self, gray_image, radius=1, n_points=8):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Local Binary Pattern features (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏ô)"""
        try:
            height, width = gray_image.shape
            lbp_features = []
            
            # LBP computation (‡∏ó‡∏≥‡∏ó‡∏∏‡∏Å‡∏à‡∏∏‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏Å‡πà‡∏≠‡∏ô)
            # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            small_gray = cv2.resize(gray_image, (56, 56))  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î
            h, w = small_gray.shape
            
            for i in range(radius, h - radius):
                for j in range(radius, w - radius):
                    center = small_gray[i, j]
                    binary_string = ''
                    
                    # 8-neighborhood
                    neighbors = [
                        small_gray[i-1, j-1], small_gray[i-1, j], small_gray[i-1, j+1],
                        small_gray[i, j+1], small_gray[i+1, j+1], small_gray[i+1, j],
                        small_gray[i+1, j-1], small_gray[i, j-1]
                    ]
                    
                    for neighbor in neighbors:
                        binary_string += '1' if neighbor >= center else '0'
                    
                    lbp_features.append(int(binary_string, 2))
            
            # Create histogram of LBP values (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏ô)
            if lbp_features:
                hist, _ = np.histogram(lbp_features, bins=16, range=(0, 256))
                return hist.tolist()
            else:
                return [0] * 16
                
        except Exception as e:
            print(f"Error computing LBP features: {e}")
            return [0] * 16
    
    def preprocess_image(self, image: np.ndarray) -> Optional[np.ndarray]:
        """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (wrapper ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö extract_features)"""
        return self.extract_features(image)
    
    def predict(self, image: np.ndarray) -> Dict:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
        if self.model is None:
            return {
                "success": False,
                "error": "Model not loaded",
                "predicted_class": None,
                "confidence": 0.0,
                "probabilities": {}
            }
        
        try:
            # ‡∏™‡∏Å‡∏±‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            features = self.extract_features(image)
            if features is None:
                return {
                    "success": False,
                    "error": "Failed to extract features from image",
                    "predicted_class": None,
                    "confidence": 0.0,
                    "probabilities": {}
                }
            
            # ‡πÉ‡∏ä‡πâ scaler ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if self.scaler is not None:
                features = self.scaler.transform(features)
            
            # ‡πÉ‡∏ä‡πâ PCA ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if self.pca is not None:
                features = self.pca.transform(features)
            
            # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            prediction = self.model.predict(features)[0]
            probabilities = self.model.predict_proba(features)[0]
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            if self.label_encoder is not None:
                # ‡πÉ‡∏ä‡πâ label encoder ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                predicted_class = self.label_encoder.inverse_transform([prediction])[0]
            elif self.class_mapping:
                # ‡πÉ‡∏ä‡πâ class mapping
                class_names = list(self.class_mapping.keys())
                predicted_class = class_names[prediction] if prediction < len(class_names) else f"Unknown_{prediction}"
            else:
                predicted_class = f"Class_{prediction}"
            
            confidence = float(np.max(probabilities))
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á probability dictionary
            if self.label_encoder is not None:
                class_names = self.label_encoder.classes_
            elif self.class_mapping:
                class_names = list(self.class_mapping.keys())
            else:
                class_names = [f"Class_{i}" for i in range(len(probabilities))]
            
            prob_dict = {
                class_names[i]: float(prob) 
                for i, prob in enumerate(probabilities)
                if i < len(class_names)
            }
            
            return {
                "success": True,
                "predicted_class": predicted_class,
                "confidence": confidence,
                "class_index": int(prediction),
                "probabilities": prob_dict,
                "feature_count": features.shape[1],
                "model_info": {
                    "version": self.model_info.get('version', '2.0') if self.model_info else '2.0',
                    "accuracy": self.model_info.get('accuracy', 0.0) if self.model_info else 0.0,
                    "training_date": self.model_info.get('training_date', 'Unknown') if self.model_info else 'Unknown'
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Prediction failed: {str(e)}",
                "predicted_class": None,
                "confidence": 0.0,
                "probabilities": {}
            }
    
    def predict_from_file(self, image_path: str) -> Dict:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            image = cv2.imread(image_path)
            if image is None:
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ PIL
                pil_image = Image.open(image_path)
                image = np.array(pil_image.convert('RGB'))
            
            return self.predict(image)
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to load image: {str(e)}",
                "predicted_class": None,
                "confidence": 0.0,
                "probabilities": {}
            }
    
    def get_model_status(self) -> Dict:
        """‡πÑ‡∏î‡πâ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        return {
            "model_loaded": self.model is not None,
            "scaler_loaded": self.scaler is not None,
            "label_encoder_loaded": self.label_encoder is not None,
            "pca_loaded": self.pca is not None,
            "model_path": str(self.model_path),
            "num_classes": len(self.class_mapping) if self.class_mapping else 0,
            "class_names": list(self.class_mapping.keys()) if self.class_mapping else [],
            "image_size": self.image_size,
            "model_info": self.model_info
        }

# Global classifier instance
updated_classifier = None

def get_updated_classifier() -> UpdatedAmuletClassifier:
    """‡πÑ‡∏î‡πâ classifier instance (singleton pattern)"""
    global updated_classifier
    if updated_classifier is None:
        updated_classifier = UpdatedAmuletClassifier()
        # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        try:
            updated_classifier.load_model()
            print("üéØ Auto-loaded trained model successfully!")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not auto-load model: {e}")
    return updated_classifier

def predict_image_file(image_path: str) -> Dict:
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö frontend)"""
    try:
        classifier = get_updated_classifier()
        return classifier.predict_from_file(image_path)
    except Exception as e:
        return {
            "success": False,
            "error": f"Failed to predict image: {str(e)}",
            "predicted_class": None,
            "confidence": 0.0,
            "probabilities": {}
        }

def predict_image_array(image_array: np.ndarray) -> Dict:
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å numpy array (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö frontend)"""
    try:
        classifier = get_updated_classifier()
        return classifier.predict(image_array)
    except Exception as e:
        return {
            "success": False,
            "error": f"Failed to predict image: {str(e)}",
            "predicted_class": None,
            "confidence": 0.0,
            "probabilities": {}
        }

def check_model_availability() -> Dict:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    try:
        classifier = get_updated_classifier()
        status = classifier.get_model_status()
        return {
            "available": status["model_loaded"],
            "status": status,
            "message": "Model ready for predictions" if status["model_loaded"] else "Model not loaded"
        }
    except Exception as e:
        return {
            "available": False,
            "status": None,
            "message": f"Error checking model: {str(e)}"
        }

def test_model():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    print("=== Testing Updated Amulet Classifier ===")
    
    classifier = UpdatedAmuletClassifier()
    success = classifier.load_model()
    
    if success:
        status = classifier.get_model_status()
        print(f"‚úÖ Model Status:")
        print(f"   üìÅ Path: {status['model_path']}")
        print(f"   üè∑Ô∏è Classes: {status['num_classes']}")
        print(f"   üìã Class names: {status['class_names']}")
        print(f"   üìê Image size: {status['image_size']}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏î‡∏™‡∏≠‡∏ö
        test_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        print(f"\nüß™ Testing with random image shape: {test_image.shape}")
        
        result = classifier.predict(test_image)
        if result['success']:
            print(f"‚úÖ Test Prediction:")
            print(f"   üîÆ Predicted: {result['predicted_class']}")
            print(f"   üìä Confidence: {result['confidence']:.4f}")
            print(f"   üéØ Features extracted: {result.get('feature_count', 'Unknown')}")
            print(f"   üìà Top 3 probabilities:")
            
            # ‡πÅ‡∏™‡∏î‡∏á top 3 probabilities
            sorted_probs = sorted(result['probabilities'].items(), 
                                key=lambda x: x[1], reverse=True)[:3]
            for class_name, prob in sorted_probs:
                print(f"      {class_name}: {prob:.4f}")
        else:
            print(f"‚ùå Test Prediction Failed: {result['error']}")
    else:
        print("‚ùå Failed to load model")
        print("üí° Make sure you have trained a model first using train_ai_model.py")

if __name__ == "__main__":
    test_model()